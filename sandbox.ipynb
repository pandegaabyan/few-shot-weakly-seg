{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Metric\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "from learners.metrics import MultiIoUMetric\n",
                "\n",
                "\n",
                "metric = MultiIoUMetric()\n",
                "\n",
                "metric(torch.tensor([1, 0, 1]), torch.tensor([1, 0, 1]))\n",
                "\n",
                "metric.compute()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Utils\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.diff_dict import diff_dict\n",
                "\n",
                "\n",
                "diff_dict(\n",
                "    {\n",
                "        \"config\": {},\n",
                "        \"a\": {\"a\": {\"p\": 1}},\n",
                "        \"b\": 2,\n",
                "        \"p\": (12, 34),\n",
                "        \"d\": {\"e\": 4, \"f\": 5, \"g\": [6, 7, 8]},\n",
                "        \"g\": [6, 7, 8],\n",
                "    },\n",
                "    {\n",
                "        \"config\": {},\n",
                "        \"a\": {\"a\": {\"p\": 1, \"q\": 0}},\n",
                "        \"c\": 3,\n",
                "        \"d\": {\"e\": 4, \"f\": 5, \"g\": [6, 9, 8, {\"a\": 1}]},\n",
                "        \"g\": [6, 9],\n",
                "        \"p\": (12, 33, 34),\n",
                "    },\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import datetime\n",
                "\n",
                "\n",
                "for item in os.listdir(\"logs/SL\"):\n",
                "    mtime = os.path.getmtime(os.path.join(\"logs/SL\", item))\n",
                "    print(datetime.datetime.fromtimestamp(mtime).isoformat())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_batch_sample_indices(\n",
                "    population_size: int, sample_size: int, batch_size: int\n",
                ") -> list[list[int]]:\n",
                "    import random\n",
                "\n",
                "    samples = sorted(random.sample(range(population_size), sample_size))\n",
                "    population_batch_size = population_size // batch_size + 1\n",
                "    batch_samples = [[] for _ in range(population_batch_size)]\n",
                "    for s in samples:\n",
                "        batch_samples[s // batch_size].append(s - (s // batch_size) * batch_size)\n",
                "    return batch_samples\n",
                "\n",
                "\n",
                "make_batch_sample_indices(100, 10, 20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_batch_sample_indices_multi(\n",
                "    iterations_batches: list[tuple[int, int]], total_samples: int\n",
                ") -> list[list[int]]:\n",
                "    import random\n",
                "\n",
                "    populations = [iter * batch for iter, batch in iterations_batches]\n",
                "\n",
                "    sum_populations = sum(populations)\n",
                "    samples = [round(p * total_samples / sum_populations) for p in populations]\n",
                "    while True:\n",
                "        sum_samples = sum(samples)\n",
                "        if sum_samples == total_samples:\n",
                "            break\n",
                "        index = random.randint(0, len(samples) - 1)\n",
                "        samples[index] += 1 if sum_samples < total_samples else -1\n",
                "\n",
                "    batch_samples = []\n",
                "    zipped = zip(iterations_batches, populations, samples)\n",
                "    for (_, batch), population, sample in zipped:\n",
                "        batch_samples += make_batch_sample_indices(\n",
                "            population,\n",
                "            sample,\n",
                "            batch,\n",
                "        )\n",
                "\n",
                "    return batch_samples\n",
                "\n",
                "\n",
                "make_batch_sample_indices_multi([(5, 3), (4, 2), (10, 1)], 20)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## WandB\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import wandb\n",
                "\n",
                "from config.constants import WANDB_SETTINGS\n",
                "from utils.wandb import wandb_login"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def wandb_log_dataset_ref(dataset_path: str, dataset_name: str, dummy: bool = False):\n",
                "    wandb_login()\n",
                "    wandb.init(\n",
                "        tags=[\"helper\"],\n",
                "        project=WANDB_SETTINGS[\"dummy_project\" if dummy else \"project\"],\n",
                "        name=f\"log dataset {dataset_name}\",\n",
                "    )\n",
                "    dataset_artifact = wandb.Artifact(dataset_name, type=\"dataset\")\n",
                "    dataset_artifact.add_reference(f\"file://{dataset_path}\")\n",
                "    wandb.log_artifact(dataset_artifact)\n",
                "    wandb.finish()\n",
                "\n",
                "\n",
                "wandb_log_dataset_ref(\"D:/Penelitian/FWS/data/REFUGE-train\", \"REFUGE-train\", True)\n",
                "wandb_log_dataset_ref(\"D:/Penelitian/FWS/data/REFUGE-val\", \"REFUGE-val\", True)\n",
                "wandb_log_dataset_ref(\"D:/Penelitian/FWS/data/REFUGE-test\", \"REFUGE-test\", True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ac = wandb.Api().artifact_collection(\n",
                "#     \"run_table\", \"pandegaaz/few-shot-weakly-seg-old/run-svgff5kf-metrics\"\n",
                "# )\n",
                "\n",
                "# ac.delete()\n",
                "\n",
                "# for art in ac.artifacts():\n",
                "#     print(art.name, art.id)\n",
                "\n",
                "# art: wandb.Artifact = ac.artifacts()[0]  # type: ignore\n",
                "\n",
                "# print(art.name, art.aliases)\n",
                "\n",
                "# art.download(\"ppp/qqq\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Aiven\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import requests\n",
                "import time\n",
                "from typing import Literal\n",
                "\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "\n",
                "def turn_aiven_db(state: Literal[\"on\", \"off\"]):\n",
                "    url = (\n",
                "        \"https://api.aiven.io/v1/project/few-shot-weakly-seg/service/optuna-postgres-db\"\n",
                "    )\n",
                "    load_dotenv()\n",
                "    aiven_token = os.getenv(\"AIVEN_API_TOKEN\")\n",
                "    auth_headers = {\"Authorization\": f\"aivenv1 {aiven_token}\"}\n",
                "\n",
                "    res = requests.put(\n",
                "        url,\n",
                "        json={\"powered\": True if state == \"on\" else False},\n",
                "        params={\"allow_unclean_poweroff\": \"false\"},\n",
                "        headers=auth_headers,\n",
                "    )\n",
                "    if res.status_code != 200:\n",
                "        raise ValueError(\n",
                "            f\"Failed to turn db {state}, response {res.status_code}: {res.text}\"\n",
                "        )\n",
                "\n",
                "    if state == \"off\":\n",
                "        print(\"Successfully turned off db\")\n",
                "        return\n",
                "\n",
                "    print(\"Waiting for db to turn on\")\n",
                "    while True:\n",
                "        res = requests.get(url, headers=auth_headers)\n",
                "        if res.status_code != 200:\n",
                "            raise ValueError(\n",
                "                f\"Failed to get db status, response {res.status_code}: {res.text}\"\n",
                "            )\n",
                "        if res.json()[\"service\"][\"state\"] == \"RUNNING\":\n",
                "            break\n",
                "        time.sleep(10)\n",
                "    print(\"Successfully turned on db\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# turn_aiven_db(\"off\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Lightning Issue\n",
                "\n",
                "https://github.com/Lightning-AI/pytorch-lightning/issues/20095\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from torch import nn\n",
                "from torch.utils.data import TensorDataset, DataLoader\n",
                "\n",
                "from pytorch_lightning import LightningModule, Trainer\n",
                "from pytorch_lightning.loggers import TensorBoardLogger\n",
                "from torch.utils.tensorboard.writer import SummaryWriter\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleModel(LightningModule):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.conv = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
                "        self.loss = torch.nn.CrossEntropyLoss()\n",
                "\n",
                "    def forward(self, x):\n",
                "        out = self.conv(x)\n",
                "        out = nn.functional.interpolate(\n",
                "            out, x.size()[2:], mode=\"bilinear\"\n",
                "        )  # main error\n",
                "        return out\n",
                "\n",
                "    def configure_optimizers(self):\n",
                "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
                "\n",
                "    def on_fit_start(self):\n",
                "        super().on_fit_start()\n",
                "        self.log_graph()\n",
                "\n",
                "    def training_step(self, batch, batch_idx):\n",
                "        x, y = batch\n",
                "        pred = self(x)\n",
                "        loss = self.loss(pred, y)\n",
                "        return loss\n",
                "\n",
                "    def log_graph(self, inp=None):\n",
                "        if inp is None:\n",
                "            inp = torch.randn(8, 3, 64, 64, device=self.device)\n",
                "\n",
                "        self.to_onnx(\"model.onnx\", inp, export_params=False)\n",
                "\n",
                "        if isinstance(self.logger, TensorBoardLogger):\n",
                "            self.logger.log_graph(self, inp)\n",
                "\n",
                "        tensorboard_writer = SummaryWriter(\"tensorboard/manual\")\n",
                "        tensorboard_writer.add_graph(self, inp)\n",
                "        tensorboard_writer.close()\n",
                "\n",
                "\n",
                "model = SimpleModel()\n",
                "train_dataset = TensorDataset(\n",
                "    torch.randn(20, 3, 64, 64), torch.randint(0, 3, (20, 64, 64))\n",
                ")\n",
                "train_loader = DataLoader(train_dataset, batch_size=8)\n",
                "\n",
                "# model.log_graph(torch.randn(8, 3, 64, 64, device=model.device))\n",
                "\n",
                "trainer = Trainer(\n",
                "    deterministic=\"warn\",\n",
                "    accelerator=\"gpu\",\n",
                "    max_epochs=1,\n",
                "    logger=TensorBoardLogger(\"tensorboard\", name=\"auto\", log_graph=True),\n",
                "    enable_checkpointing=False,\n",
                ")\n",
                "# trainer.fit(model, train_loader)\n",
                "\n",
                "# model.log_graph(torch.randn(8, 3, 64, 64, device=model.device))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Other\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
