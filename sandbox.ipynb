{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Metric\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "from learners.metrics import MultiIoUMetric\n",
                "\n",
                "\n",
                "metric = MultiIoUMetric()\n",
                "\n",
                "metric(torch.tensor([1, 0, 1]), torch.tensor([1, 0, 1]))\n",
                "\n",
                "metric.compute()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Utils\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils.diff_dict import diff_dict\n",
                "\n",
                "\n",
                "diff_dict(\n",
                "    {\n",
                "        \"config\": {},\n",
                "        \"a\": {\"a\": {\"p\": 1}},\n",
                "        \"b\": 2,\n",
                "        \"p\": (12, 34),\n",
                "        \"d\": {\"e\": 4, \"f\": 5, \"g\": [6, 7, 8]},\n",
                "        \"g\": [6, 7, 8],\n",
                "    },\n",
                "    {\n",
                "        \"config\": {},\n",
                "        \"a\": {\"a\": {\"p\": 1, \"q\": 0}},\n",
                "        \"c\": 3,\n",
                "        \"d\": {\"e\": 4, \"f\": 5, \"g\": [6, 9, 8, {\"a\": 1}]},\n",
                "        \"g\": [6, 9],\n",
                "        \"p\": (12, 33, 34),\n",
                "    },\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import datetime\n",
                "\n",
                "\n",
                "for item in os.listdir(\"logs/SL\"):\n",
                "    mtime = os.path.getmtime(os.path.join(\"logs/SL\", item))\n",
                "    print(datetime.datetime.fromtimestamp(mtime).isoformat())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_batch_sample_indices(\n",
                "    population_size: int, sample_size: int, batch_size: int\n",
                ") -> list[list[int]]:\n",
                "    import random\n",
                "\n",
                "    samples = sorted(random.sample(range(population_size), sample_size))\n",
                "    population_batch_size = population_size // batch_size + 1\n",
                "    batch_samples = [[] for _ in range(population_batch_size)]\n",
                "    for s in samples:\n",
                "        batch_samples[s // batch_size].append(s - (s // batch_size) * batch_size)\n",
                "    return batch_samples\n",
                "\n",
                "\n",
                "make_batch_sample_indices(100, 10, 20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_batch_sample_indices_multi(\n",
                "    iterations_batches: list[tuple[int, int]], total_samples: int\n",
                ") -> list[list[int]]:\n",
                "    import random\n",
                "\n",
                "    populations = [iter * batch for iter, batch in iterations_batches]\n",
                "\n",
                "    sum_populations = sum(populations)\n",
                "    samples = [round(p * total_samples / sum_populations) for p in populations]\n",
                "    while True:\n",
                "        sum_samples = sum(samples)\n",
                "        if sum_samples == total_samples:\n",
                "            break\n",
                "        index = random.randint(0, len(samples) - 1)\n",
                "        samples[index] += 1 if sum_samples < total_samples else -1\n",
                "\n",
                "    batch_samples = []\n",
                "    zipped = zip(iterations_batches, populations, samples)\n",
                "    for (_, batch), population, sample in zipped:\n",
                "        batch_samples += make_batch_sample_indices(\n",
                "            population,\n",
                "            sample,\n",
                "            batch,\n",
                "        )\n",
                "\n",
                "    return batch_samples\n",
                "\n",
                "\n",
                "make_batch_sample_indices_multi([(5, 3), (4, 2), (10, 1)], 20)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## WandB\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import wandb\n",
                "\n",
                "from utils.wandb import wandb_login, get_wandb_project"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def wandb_log_dataset_ref(dataset_path: str, dataset_name: str, dummy: bool = False):\n",
                "    wandb_login()\n",
                "    wandb.init(\n",
                "        tags=[\"helper\"],\n",
                "        project=get_wandb_project(dummy),\n",
                "        name=f\"log dataset {dataset_name}\",\n",
                "    )\n",
                "    dataset_artifact = wandb.Artifact(dataset_name, type=\"dataset\")\n",
                "    dataset_artifact.add_reference(f\"file://{dataset_path}\")\n",
                "    wandb.log_artifact(dataset_artifact)\n",
                "    wandb.finish()\n",
                "\n",
                "\n",
                "# wandb_log_dataset_ref(\"D:/Penelitian/FWS/data/REFUGE-train\", \"REFUGE-train\", True)\n",
                "# wandb_log_dataset_ref(\"D:/Penelitian/FWS/data/REFUGE-val\", \"REFUGE-val\", True)\n",
                "# wandb_log_dataset_ref(\"D:/Penelitian/FWS/data/REFUGE-test\", \"REFUGE-test\", True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ac = wandb.Api().artifact_collection(\n",
                "#     \"run_table\", \"pandegaaz/few-shot-weakly-seg-old/run-svgff5kf-metrics\"\n",
                "# )\n",
                "\n",
                "# ac.delete()\n",
                "\n",
                "# for art in ac.artifacts():\n",
                "#     print(art.name, art.id)\n",
                "\n",
                "# art: wandb.Artifact = ac.artifacts()[0]  # type: ignore\n",
                "\n",
                "# print(art.name, art.aliases)\n",
                "\n",
                "# art.download(\"ppp/qqq\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import os\n",
                "# from utils.wandb import prepare_study_ckpt_artifact_name, prepare_ckpt_artifact_alias, wandb_log_file\n",
                "\n",
                "# wandb_login()\n",
                "# wandb.init(\n",
                "#     tags=[\"helper\"],\n",
                "#     project=get_wandb_project(False),\n",
                "#     name=\"log ckpts\",\n",
                "# )\n",
                "\n",
                "# ckpts = sorted(filter(lambda x: x.endswith(\".ckpt\"), os.listdir(os.getcwd())))\n",
                "# for ckpt in ckpts:\n",
                "#     study_id = ckpt.split(\"=\")[-1].split(\".\")[0]\n",
                "#     artifact_name = prepare_study_ckpt_artifact_name(study_id)\n",
                "#     new_ckpt = ckpt.split(\" study\")[0].replace(\"F=\", \"fold=\") + \".ckpt\"\n",
                "#     artifact_alias = prepare_ckpt_artifact_alias(new_ckpt)\n",
                "#     artifact_path = os.path.join(os.getcwd(), new_ckpt)\n",
                "#     os.rename(ckpt, new_ckpt)\n",
                "#     wandb_log_file(\n",
                "#         wandb.run,\n",
                "#         artifact_name,\n",
                "#         artifact_path,\n",
                "#         \"study-checkpoint\",\n",
                "#         [artifact_alias],\n",
                "#     )\n",
                "#     print(ckpt, artifact_name, artifact_alias, new_ckpt, sep=\" | \")\n",
                "\n",
                "# wandb.finish()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from utils.wandb import wandb_path\n",
                "\n",
                "# runs = wandb.Api().runs(\n",
                "#     wandb_path(False),\n",
                "#     filters={\"config.dataset\": \"RIM-ONE-3-train\", \"config.study\": {\"$ne\": \"8kcKT\"}},\n",
                "# )\n",
                "\n",
                "# for i, run in enumerate(runs):\n",
                "#     print(i, run.name)\n",
                "#     run.config[\"study\"] = \"8kcKT\"\n",
                "#     run.update()\n",
                "\n",
                "# runs = wandb.Api().runs(\n",
                "#     wandb_path(False),\n",
                "#     filters={\"display_name\":\"2024-09-13 05-37 eRF\"},\n",
                "# )\n",
                "\n",
                "# for i, run in enumerate(runs):\n",
                "#     print(i, run.name, run.group)\n",
                "#     run.group = \"WS multi-step\"\n",
                "#     run.update()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "from utils.wandb import wandb_use_alert\n",
                "\n",
                "\n",
                "def dummy_alert():\n",
                "    with wandb_use_alert():\n",
                "        print(\"Sleep...\")\n",
                "        time.sleep(30)\n",
                "        raise ValueError(\"Dummy alert\")\n",
                "\n",
                "\n",
                "# wandb_login()\n",
                "# wandb.init(project=get_wandb_project(True), name=\"check alert\", group=\"dummy\")\n",
                "# dummy_alert()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Aiven\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import requests\n",
                "import time\n",
                "from typing import Literal\n",
                "\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "\n",
                "def turn_aiven_db(state: Literal[\"on\", \"off\"]):\n",
                "    url = (\n",
                "        \"https://api.aiven.io/v1/project/few-shot-weakly-seg/service/optuna-postgres-db\"\n",
                "    )\n",
                "    load_dotenv()\n",
                "    aiven_token = os.getenv(\"AIVEN_API_TOKEN\")\n",
                "    auth_headers = {\"Authorization\": f\"aivenv1 {aiven_token}\"}\n",
                "\n",
                "    res = requests.put(\n",
                "        url,\n",
                "        json={\"powered\": True if state == \"on\" else False},\n",
                "        params={\"allow_unclean_poweroff\": \"false\"},\n",
                "        headers=auth_headers,\n",
                "    )\n",
                "    if res.status_code != 200:\n",
                "        raise ValueError(\n",
                "            f\"Failed to turn db {state}, response {res.status_code}: {res.text}\"\n",
                "        )\n",
                "\n",
                "    if state == \"off\":\n",
                "        print(\"Successfully turned off db\")\n",
                "        return\n",
                "\n",
                "    print(\"Waiting for db to turn on\")\n",
                "    while True:\n",
                "        res = requests.get(url, headers=auth_headers)\n",
                "        if res.status_code != 200:\n",
                "            raise ValueError(\n",
                "                f\"Failed to get db status, response {res.status_code}: {res.text}\"\n",
                "            )\n",
                "        if res.json()[\"service\"][\"state\"] == \"RUNNING\":\n",
                "            break\n",
                "        time.sleep(10)\n",
                "    print(\"Successfully turned on db\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# turn_aiven_db(\"off\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Lightning Issue\n",
                "\n",
                "https://github.com/Lightning-AI/pytorch-lightning/issues/20095\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from torch import nn\n",
                "from torch.utils.data import TensorDataset, DataLoader\n",
                "\n",
                "from pytorch_lightning import LightningModule, Trainer\n",
                "from pytorch_lightning.loggers import TensorBoardLogger\n",
                "from torch.utils.tensorboard.writer import SummaryWriter\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleModel(LightningModule):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.conv = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
                "        self.loss = torch.nn.CrossEntropyLoss()\n",
                "\n",
                "    def forward(self, x):\n",
                "        out = self.conv(x)\n",
                "        out = nn.functional.interpolate(\n",
                "            out, x.size()[2:], mode=\"bilinear\"\n",
                "        )  # main error\n",
                "        return out\n",
                "\n",
                "    def configure_optimizers(self):\n",
                "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
                "\n",
                "    def on_fit_start(self):\n",
                "        super().on_fit_start()\n",
                "        self.log_graph()\n",
                "\n",
                "    def training_step(self, batch, batch_idx):\n",
                "        x, y = batch\n",
                "        pred = self(x)\n",
                "        loss = self.loss(pred, y)\n",
                "        return loss\n",
                "\n",
                "    def log_graph(self, inp=None):\n",
                "        if inp is None:\n",
                "            inp = torch.randn(8, 3, 64, 64, device=self.device)\n",
                "\n",
                "        self.to_onnx(\"model.onnx\", inp, export_params=False)\n",
                "\n",
                "        if isinstance(self.logger, TensorBoardLogger):\n",
                "            self.logger.log_graph(self, inp)\n",
                "\n",
                "        tensorboard_writer = SummaryWriter(\"tensorboard/manual\")\n",
                "        tensorboard_writer.add_graph(self, inp)\n",
                "        tensorboard_writer.close()\n",
                "\n",
                "\n",
                "model = SimpleModel()\n",
                "train_dataset = TensorDataset(\n",
                "    torch.randn(20, 3, 64, 64), torch.randint(0, 3, (20, 64, 64))\n",
                ")\n",
                "train_loader = DataLoader(train_dataset, batch_size=8)\n",
                "\n",
                "# model.log_graph(torch.randn(8, 3, 64, 64, device=model.device))\n",
                "\n",
                "trainer = Trainer(\n",
                "    deterministic=\"warn\",\n",
                "    accelerator=\"gpu\",\n",
                "    max_epochs=1,\n",
                "    logger=TensorBoardLogger(\"tensorboard\", name=\"auto\", log_graph=True),\n",
                "    enable_checkpointing=False,\n",
                ")\n",
                "# trainer.fit(model, train_loader)\n",
                "\n",
                "# model.log_graph(torch.randn(8, 3, 64, 64, device=model.device))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Study Time\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_study_time(train_size: int, val_size: int, num_folds: int) -> float:\n",
                "    return train_size / 100 * 4 * num_folds + val_size / 100 * 2 * num_folds + 1\n",
                "\n",
                "\n",
                "print(get_study_time(45, 5, 3) * 10)\n",
                "print(get_study_time(80, 20, 3) * 10)\n",
                "print(get_study_time(320, 80, 3) * 10)\n",
                "print(get_study_time(400, 400, 1) * 10)\n",
                "print(get_study_time(45 + 80 + 320, 5 + 20 + 80, 3) * 10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Weight Averaging\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "from copy import deepcopy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "ckpt0 = torch.load(\n",
                "    \"logs/PS/best study 3UQpU/val_score=0.8294 epoch=11 fold=0 trial=40.ckpt\"\n",
                ")\n",
                "ckpt1 = torch.load(\n",
                "    \"logs/PS/best study 3UQpU/val_score=0.7772 epoch=17 fold=1 trial=40.ckpt\"\n",
                ")\n",
                "\n",
                "ckpt = deepcopy(ckpt0)\n",
                "weight = {\n",
                "    k: (v + ckpt1[\"state_dict\"][k]) / 2\n",
                "    for k, v in ckpt0[\"state_dict\"].items()\n",
                "    if k.startswith(\"net.\")\n",
                "}\n",
                "ckpt[\"state_dict\"].update(weight)\n",
                "# torch.save(ckpt, \"logs/PS/best study 3UQpU/merged.ckpt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Resize Images\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "from skimage import transform\n",
                "from skimage import io\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def resize_image(img, is_mask: bool):\n",
                "    dtype = img.dtype\n",
                "    s1, s2 = img.shape[:2]\n",
                "    smax = max(s1, s2)\n",
                "    if smax <= 1024:\n",
                "        return img\n",
                "\n",
                "    if s1 == smax:\n",
                "        output_shape = (1024, round(1024 * s2 / s1))\n",
                "    else:\n",
                "        output_shape = (round(1024 * s1 / s2), 1024)\n",
                "\n",
                "    if is_mask:\n",
                "        order = 0\n",
                "        anti_aliasing = False\n",
                "    else:\n",
                "        order = 1\n",
                "        anti_aliasing = True\n",
                "\n",
                "    resized = transform.resize(\n",
                "        img,\n",
                "        output_shape,\n",
                "        order=order,\n",
                "        preserve_range=True,\n",
                "        anti_aliasing=anti_aliasing,\n",
                "    )\n",
                "    resized = resized.astype(dtype)\n",
                "\n",
                "    return resized"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "paths = [\n",
                "    \"../data/ISIC2016/old_input\",\n",
                "    \"../data/ISIC2016/old_mask\",\n",
                "    \"../data/ISIC2017/old_input\",\n",
                "    \"../data/ISIC2017/old_mask\",\n",
                "    \"../data/ISIC2018/old_input\",\n",
                "    \"../data/ISIC2018/old_mask\",\n",
                "]\n",
                "\n",
                "for path in paths:\n",
                "    is_mask = \"mask\" in path\n",
                "    for item in os.listdir(path):\n",
                "        filepath = os.path.join(path, item)\n",
                "        img = io.imread(filepath, as_gray=is_mask)\n",
                "        resized = resize_image(img, is_mask)\n",
                "        io.imsave(filepath.replace(\"old_\", \"\"), resized)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Other\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
