{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Dataset and Loader\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "from matplotlib import pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dummy Dataset\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from data.dummy_dataset import DummyFSDataset, DummySimpleDataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dummy_simple_dataset = DummySimpleDataset(\n",
                "    \"val\",\n",
                "    3,\n",
                "    (256, 256),\n",
                "    max_items=100,\n",
                "    seed=0,\n",
                "    split_val_size=0.2,\n",
                "    split_val_fold=0,\n",
                "    split_test_size=0.2,\n",
                "    split_test_fold=0,\n",
                "    cache_data=False,\n",
                "    dataset_name=\"Dummy\",\n",
                ")\n",
                "\n",
                "print(len(dummy_simple_dataset))\n",
                "img, msk, name, _ = dummy_simple_dataset[79]\n",
                "\n",
                "print(\n",
                "    name,\n",
                "    img.shape,\n",
                "    img.dtype,\n",
                "    img.min(),\n",
                "    img.max(),\n",
                "    msk.shape,\n",
                "    msk.dtype,\n",
                "    torch.unique(msk),\n",
                ")\n",
                "\n",
                "plt.imshow(np.moveaxis(img.numpy(), 0, -1))\n",
                "# plt.imshow(msk.numpy())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dummy_fs_dataset = DummyFSDataset(\n",
                "    \"train\",\n",
                "    3,\n",
                "    (256, 256),\n",
                "    max_items=25,\n",
                "    seed=0,\n",
                "    split_val_size=0.2,\n",
                "    split_val_fold=0,\n",
                "    split_test_size=0.2,\n",
                "    split_test_fold=0,\n",
                "    cache_data=False,\n",
                "    dataset_name=\"Dummy\",\n",
                "    shot_options=[5, 10],\n",
                "    sparsity_options=[\n",
                "        (\"point\", [1, 5, 10, 20]),\n",
                "        # (\"grid\", (10, 20)),\n",
                "        # (\"contour\", \"random\"),\n",
                "        # (\"skeleton\", (0.1, 0.5)),\n",
                "        # (\"region\", 0.5),\n",
                "    ],\n",
                "    sparsity_params={},\n",
                "    support_query_data=\"mixed\",\n",
                "    support_batch_mode=\"mixed\",\n",
                "    query_batch_size=10,\n",
                "    split_query_size=0.5,\n",
                "    split_query_fold=0,\n",
                "    num_iterations=5.0,\n",
                ")\n",
                "\n",
                "print(len(dummy_fs_dataset.items))\n",
                "print(len(dummy_fs_dataset), dummy_fs_dataset.num_iterations)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(dummy_fs_dataset.support_batches)\n",
                "for i in range(len(dummy_fs_dataset)):\n",
                "    support, query, _ = dummy_fs_dataset[i]\n",
                "    supp_img, supp_msk, supp_name, supp_sparsity_mode, supp_sparsity_value = support\n",
                "    qry_img, qry_msk, qry_name = query\n",
                "    print(\n",
                "        supp_img.shape[0],\n",
                "        supp_msk.shape[0],\n",
                "        len(supp_name),\n",
                "        \"|\",\n",
                "        supp_sparsity_mode,\n",
                "        [round(v, 2) if isinstance(v, float) else v for v in supp_sparsity_value]\n",
                "        if isinstance(supp_sparsity_value, list)\n",
                "        else supp_sparsity_value,\n",
                "        \"|\",\n",
                "        qry_img.shape[0],\n",
                "        qry_msk.shape[0],\n",
                "        len(qry_name),\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "support, query, _ = dummy_fs_dataset[0]\n",
                "\n",
                "supp_img, supp_msk, supp_name, supp_sparsity_mode, supp_sparsity_value = support\n",
                "qry_img, qry_msk, qry_name = query\n",
                "\n",
                "print(\n",
                "    supp_img.shape,\n",
                "    supp_img.dtype,\n",
                "    supp_img.min(),\n",
                "    supp_img.max(),\n",
                "    supp_msk.shape,\n",
                "    supp_msk.dtype,\n",
                "    torch.unique(supp_msk),\n",
                ")\n",
                "print(supp_name, supp_sparsity_mode, supp_sparsity_value)\n",
                "print(\n",
                "    qry_img.shape,\n",
                "    qry_img.dtype,\n",
                "    qry_img.min(),\n",
                "    qry_img.max(),\n",
                "    qry_msk.shape,\n",
                "    qry_msk.dtype,\n",
                "    torch.unique(qry_msk),\n",
                ")\n",
                "print(qry_name)\n",
                "print()\n",
                "\n",
                "# plt.imshow(supp_msk[0].numpy())\n",
                "# plt.imshow(qry_msk[0].numpy())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dummy Loader\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch.utils.data import ConcatDataset, DataLoader\n",
                "\n",
                "dummy_loader = DataLoader(\n",
                "    ConcatDataset([dummy_fs_dataset]),\n",
                "    batch_size=None,\n",
                "    shuffle=dummy_fs_dataset.mode == \"train\",\n",
                "    num_workers=0,\n",
                "    pin_memory=True,\n",
                ")\n",
                "\n",
                "for batch in dummy_loader:\n",
                "    support, query, dataset_name = batch\n",
                "\n",
                "    print(type(batch.support))\n",
                "    print(support[0].shape, support[1].shape, support[2][:4], support[3])\n",
                "    print(query[0].shape, query[1].shape, query[2])\n",
                "    print(dataset_name)\n",
                "\n",
                "    break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sparse Masks\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from matplotlib import pyplot as plt\n",
                "\n",
                "from data.few_sparse_dataset import FewSparseDataset\n",
                "from data.typings import SparsityValue\n",
                "from tasks.optic_disc_cup.datasets import (\n",
                "    RimOne3TrainFSDataset,\n",
                "    DrishtiTrainFSDataset,\n",
                "    RefugeTrainFSDataset,\n",
                "    RefugeValFSDataset,\n",
                ")\n",
                "\n",
                "plt.style.use(\"dark_background\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "sparsity_values: dict[str, SparsityValue] = {\n",
                "    \"point\": 25,\n",
                "    \"grid\": 0.5,\n",
                "    \"contour\": 0.5,\n",
                "    \"skeleton\": 0.5,\n",
                "    \"region\": 0.5,\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def print_image_mask(image, mask):\n",
                "    print(image.shape, image.dtype, image.min(), image.max())\n",
                "    print(mask.shape, mask.dtype, np.unique(mask))\n",
                "\n",
                "\n",
                "def plot_masks(mask, sparse_masks):\n",
                "    n_rows = int(np.floor(len(sparse_masks) / 2)) + 1\n",
                "    _, axs = plt.subplots(n_rows, 2, figsize=(5, n_rows * 2.5))\n",
                "    assert isinstance(axs, np.ndarray)\n",
                "    axs = axs.flat\n",
                "    [ax.axis(\"off\") for ax in axs]\n",
                "    axs[0].imshow(mask)\n",
                "    for i, sm in enumerate(sparse_masks.values()):\n",
                "        axs[i + 1].imshow(sm)\n",
                "    plt.tight_layout()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_multiple_images_masks(\n",
                "    dataset: FewSparseDataset, indices: list[int], keys: list[str]\n",
                "):\n",
                "    ncols = len(indices)\n",
                "    nrows = len(keys)\n",
                "    _, axs = plt.subplots(nrows, ncols, figsize=(ncols * 2, nrows * 2))\n",
                "    assert isinstance(axs, np.ndarray)\n",
                "    for c, index in enumerate(indices):\n",
                "        image, mask, sparse_masks, _ = dataset.get_data_with_sparse_all(\n",
                "            index, sparsity_values\n",
                "        )\n",
                "        r = 0\n",
                "        if \"image\" in keys:\n",
                "            axs[r, c].imshow(image)\n",
                "            axs[r, c].axis(\"off\")\n",
                "            r += 1\n",
                "        if \"dense\" in keys:\n",
                "            axs[r, c].imshow(mask)\n",
                "            axs[r, c].axis(\"off\")\n",
                "            r += 1\n",
                "        for key, sm in sparse_masks.items():\n",
                "            if key not in keys:\n",
                "                continue\n",
                "            axs[r, c].imshow(sm)\n",
                "            axs[r, c].axis(\"off\")\n",
                "            r += 1\n",
                "    plt.tight_layout()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## RIM-ONE-3-train\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rim_one_3_sparsity_params: dict = {\n",
                "    \"point_dot_size\": 10,\n",
                "    \"grid_spacing\": 25,\n",
                "    \"grid_dot_size\": 7,\n",
                "    \"contour_radius_dist\": 5,\n",
                "    \"contour_radius_thick\": 2.5,\n",
                "    \"skeleton_radius_thick\": 5,\n",
                "    \"region_compactness\": 0.4,\n",
                "}\n",
                "\n",
                "rim_one_3_train_data = RimOne3TrainFSDataset(\n",
                "    mode=\"train\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    sparsity_params=rim_one_3_sparsity_params,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# image, mask, sparse_masks, _ = rim_one_3_data.get_data_with_sparse_all(0, sparsity_values)\n",
                "# print_image_mask(image, mask)\n",
                "# plot_masks(mask, sparse_masks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_multiple_images_masks(\n",
                "    rim_one_3_train_data,\n",
                "    list(range(0, 8)),\n",
                "    [\"point\", \"grid\", \"contour\", \"skeleton\", \"region\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## DRISHTI-GS-train\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "drishti_sparsity_params: dict = {\n",
                "    \"point_dot_size\": 10,\n",
                "    \"grid_spacing\": 25,\n",
                "    \"grid_dot_size\": 7,\n",
                "    \"contour_radius_dist\": 5,\n",
                "    \"contour_radius_thick\": 2,\n",
                "    \"skeleton_radius_thick\": 5,\n",
                "    \"region_compactness\": 0.5,\n",
                "}\n",
                "\n",
                "drishti_train_data = DrishtiTrainFSDataset(\n",
                "    mode=\"train\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    sparsity_params=drishti_sparsity_params,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_multiple_images_masks(\n",
                "    drishti_train_data,\n",
                "    list(range(0, 8)),\n",
                "    [\"point\", \"grid\", \"contour\", \"skeleton\", \"region\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## REFUGE-train\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "refuge_train_sparsity_params: dict = {\n",
                "    \"point_dot_size\": 10,\n",
                "    \"grid_spacing\": 25,\n",
                "    \"grid_dot_size\": 7,\n",
                "    \"contour_radius_dist\": 7,\n",
                "    \"contour_radius_thick\": 3,\n",
                "    \"skeleton_radius_thick\": 5,\n",
                "    \"region_compactness\": 0.4,\n",
                "}\n",
                "\n",
                "refuge_train_data = RefugeTrainFSDataset(\n",
                "    mode=\"train\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    sparsity_params=refuge_train_sparsity_params,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_multiple_images_masks(\n",
                "    refuge_train_data,\n",
                "    list(range(0, 8)),\n",
                "    [\"point\", \"grid\", \"contour\", \"skeleton\", \"region\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## REFUGE-val\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "refuge_val_sparsity_params: dict = {\n",
                "    \"point_dot_size\": 10,\n",
                "    \"grid_spacing\": 25,\n",
                "    \"grid_dot_size\": 7,\n",
                "    \"contour_radius_dist\": 7,\n",
                "    \"contour_radius_thick\": 3,\n",
                "    \"skeleton_radius_thick\": 5,\n",
                "    \"region_compactness\": 0.5,\n",
                "}\n",
                "\n",
                "refuge_val_data = RefugeValFSDataset(\n",
                "    mode=\"train\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    sparsity_params=refuge_val_sparsity_params,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_multiple_images_masks(\n",
                "    refuge_val_data,\n",
                "    list(range(0, 8)),\n",
                "    [\"point\", \"grid\", \"contour\", \"skeleton\", \"region\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Publications\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.style.use(\"default\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "refuge_train_sparsity_params: dict = {\n",
                "    \"point_dot_size\": 10,\n",
                "    \"grid_spacing\": 25,\n",
                "    \"grid_dot_size\": 7,\n",
                "    \"contour_radius_dist\": 7,\n",
                "    \"contour_radius_thick\": 3,\n",
                "    \"skeleton_radius_thick\": 5,\n",
                "    \"region_compactness\": 0.4,\n",
                "}\n",
                "\n",
                "refuge_train_data = RefugeTrainFSDataset(\n",
                "    mode=\"train\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    sparsity_params=refuge_train_sparsity_params,\n",
                ")\n",
                "\n",
                "image, mask, _ = refuge_train_data.get_data(11)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_, axs = plt.subplots(1, 1, figsize=(9, 9))\n",
                "axs.axis(\"off\")\n",
                "axs.imshow(mask)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_, axs = plt.subplots(1, 4, figsize=(28, 8))\n",
                "assert isinstance(axs, np.ndarray)\n",
                "for c, sparsity_value in enumerate([13, 25, 37, 50]):\n",
                "    sparse_mask = refuge_train_data.get_sparse_mask(\n",
                "        \"point\", mask, image, sparsity_value\n",
                "    )\n",
                "    axs[c].axis(\"off\")\n",
                "    axs[c].imshow(sparse_mask)\n",
                "plt.tight_layout(pad=3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_, axs = plt.subplots(4, 4, figsize=(28, 28))\n",
                "assert isinstance(axs, np.ndarray)\n",
                "for r, sparse_mode in enumerate([\"grid\", \"contour\", \"skeleton\", \"region\"]):\n",
                "    for c, sparsity_value in enumerate([0.25, 0.5, 0.75, 1.0]):\n",
                "        sparse_mask = refuge_train_data.get_sparse_mask(\n",
                "            sparse_mode, mask, image, sparsity_value\n",
                "        )\n",
                "        axs[r, c].axis(\"off\")\n",
                "        axs[r, c].imshow(sparse_mask)\n",
                "plt.tight_layout(pad=3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Documents\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.style.use(\"default\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "refuge_train_sparsity_params: dict = {\n",
                "    \"contour_radius_dist\": 15,\n",
                "    \"contour_radius_thick\": 3,\n",
                "}\n",
                "\n",
                "refuge_train_data = RefugeTrainFSDataset(\n",
                "    mode=\"train\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    sparsity_params=refuge_train_sparsity_params,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# image, mask, _ = refuge_train_data.get_data(2)\n",
                "# mask = (mask == 2).astype(mask.dtype)\n",
                "\n",
                "# sparse_mask = refuge_train_data.get_sparse_mask(\"contour\", mask, image, 1.0)\n",
                "# sparse_mask = (sparse_mask == 1).astype(sparse_mask.dtype)\n",
                "\n",
                "# # horizontal mirror\n",
                "# image = np.flip(image, axis=1)\n",
                "# sparse_mask = np.flip(sparse_mask, axis=1)\n",
                "\n",
                "# # vertical mirror\n",
                "# image = np.flip(image, axis=0)\n",
                "# sparse_mask = np.flip(sparse_mask, axis=0)\n",
                "\n",
                "# # rotate 90 degrees\n",
                "# image = np.rot90(image)\n",
                "# sparse_mask = np.rot90(sparse_mask)\n",
                "\n",
                "# # crop\n",
                "# image = image[40:-40, 40:-40]\n",
                "# sparse_mask = sparse_mask[40:-40, 40:-40]\n",
                "\n",
                "\n",
                "# def rotate_and_crop(image, angle):\n",
                "#     from scipy.ndimage import rotate\n",
                "\n",
                "#     rotated_image = rotate(image, angle, reshape=False)\n",
                "#     h, w = rotated_image.shape[:2]\n",
                "#     crop_size = int(min(h, w) / np.sqrt(2))\n",
                "#     start_x = (w - crop_size) // 2\n",
                "#     start_y = (h - crop_size) // 2\n",
                "#     cropped_image = rotated_image[\n",
                "#         start_y : start_y + crop_size, start_x : start_x + crop_size\n",
                "#     ]\n",
                "#     return cropped_image\n",
                "\n",
                "\n",
                "# image = rotate_and_crop(image, 45)\n",
                "# sparse_mask = rotate_and_crop(sparse_mask, 45)\n",
                "\n",
                "\n",
                "# def shear_and_crop(image):\n",
                "#     from skimage.transform import AffineTransform, warp\n",
                "\n",
                "#     transform = AffineTransform(shear=(0.35, 0.0))\n",
                "#     sheared_image = warp(image, transform.inverse, mode=\"constant\", cval=0)\n",
                "#     h, w = sheared_image.shape[:2]\n",
                "#     crop_size = int(min(h, w) / np.sqrt(2))\n",
                "#     start_x = (w - crop_size) // 2\n",
                "#     start_y = (h - crop_size) // 2\n",
                "#     cropped_image = sheared_image[\n",
                "#         start_y + 4 : start_y + crop_size, start_x - 37 : start_x + crop_size - 41\n",
                "#     ]\n",
                "#     return cropped_image\n",
                "\n",
                "\n",
                "# image = shear_and_crop(image)\n",
                "# sparse_mask = shear_and_crop(sparse_mask)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# image, _, _ = refuge_train_data.get_data(2)\n",
                "\n",
                "# # increase brightness\n",
                "# image = np.clip(image * 1.5, 0, 255).astype(image.dtype)\n",
                "\n",
                "\n",
                "# def grayscale(image):\n",
                "#     from skimage.color import rgb2gray\n",
                "\n",
                "#     return rgb2gray(image)\n",
                "\n",
                "\n",
                "# image = grayscale(image)\n",
                "\n",
                "\n",
                "# def clahe(image):\n",
                "#     from skimage.exposure import equalize_adapthist\n",
                "\n",
                "#     image = equalize_adapthist(image, clip_limit=0.01)\n",
                "#     return image\n",
                "\n",
                "\n",
                "# image = clahe(image)\n",
                "\n",
                "\n",
                "# def update_gamma(image):\n",
                "#     from skimage.exposure import adjust_gamma\n",
                "\n",
                "#     return adjust_gamma(image, 1.5)  # type: ignore\n",
                "\n",
                "\n",
                "# image = update_gamma(image)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from scipy.ndimage import gaussian_filter, map_coordinates\n",
                "\n",
                "# _, mask, _ = refuge_train_data.get_data(2)\n",
                "# mask = (mask == 2).astype(mask.dtype)\n",
                "\n",
                "# sparse_mask = refuge_train_data.get_sparse_mask(\"contour\", mask, image, 1.0)\n",
                "# sparse_mask = (sparse_mask == 1).astype(sparse_mask.dtype)\n",
                "\n",
                "\n",
                "# def generate_random_displacement(shape, alpha, sigma, random_state=None):\n",
                "#     if random_state is None:\n",
                "#         random_state = np.random.RandomState(None)\n",
                "#     displacement = (random_state.rand(*shape) * 2 - 1) * alpha\n",
                "#     return gaussian_filter(displacement, sigma, mode=\"constant\", cval=0)\n",
                "\n",
                "\n",
                "# def global_displacement(image, alpha, sigma):\n",
                "#     shape = image.shape\n",
                "#     dx = generate_random_displacement(shape, alpha, sigma)\n",
                "#     dy = generate_random_displacement(shape, alpha, sigma)\n",
                "#     x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
                "#     indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1))\n",
                "#     return map_coordinates(image, indices, order=1, mode=\"reflect\").reshape(shape)\n",
                "\n",
                "\n",
                "# def directional_displacement(image, alpha, sigma, direction):\n",
                "#     shape = image.shape\n",
                "#     if direction == \"horizontal\":\n",
                "#         dx = generate_random_displacement(shape, alpha, sigma)\n",
                "#         dy = np.zeros_like(dx)\n",
                "#     elif direction == \"vertical\":\n",
                "#         dx = np.zeros_like(image)\n",
                "#         dy = generate_random_displacement(shape, alpha, sigma)\n",
                "#     x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
                "#     indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1))\n",
                "#     return map_coordinates(image, indices, order=1, mode=\"reflect\").reshape(shape)\n",
                "\n",
                "\n",
                "# def abrupt_displacement(image, alpha, sigma):\n",
                "#     shape = image.shape\n",
                "#     dx = generate_random_displacement(shape, alpha, sigma // 2)\n",
                "#     dy = generate_random_displacement(shape, alpha, sigma // 2)\n",
                "#     x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
                "#     indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1))\n",
                "#     return map_coordinates(image, indices, order=1, mode=\"reflect\").reshape(shape)\n",
                "\n",
                "\n",
                "# sparse_mask = global_displacement(sparse_mask, 150, 8)\n",
                "# sparse_mask = directional_displacement(sparse_mask,150, 8, \"vertical\")\n",
                "# sparse_mask = abrupt_displacement(sparse_mask, 30, 7)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "# image, mask, _ = refuge_train_data.get_data(2)\n",
                "# mask = (mask == 2).astype(mask.dtype)\n",
                "\n",
                "# sparse_mask = refuge_train_data.get_sparse_mask(\"contour\", mask, image, 1.0)\n",
                "# sparse_mask = (sparse_mask == 1).astype(sparse_mask.dtype)\n",
                "\n",
                "# def apply_gaussian_filter(image, sigma):\n",
                "#     from scipy.ndimage import gaussian_filter\n",
                "#     return gaussian_filter(image, sigma)\n",
                "\n",
                "# image[:, :, 0] = apply_gaussian_filter(image[:, :, 0], 8)\n",
                "# image[:, :, 1] = apply_gaussian_filter(image[:, :, 1], 8)\n",
                "# image[:, :, 2] = apply_gaussian_filter(image[:, :, 2], 8)\n",
                "\n",
                "# sparse_mask = apply_gaussian_filter(sparse_mask.astype(np.float32), 8)\n",
                "# sparse_mask = sparse_mask * (1.0 / sparse_mask.max())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from scipy.ndimage import binary_erosion, binary_dilation\n",
                "\n",
                "# _, mask, _ = refuge_train_data.get_data(2)\n",
                "# mask = (mask == 2).astype(mask.dtype)\n",
                "\n",
                "# sparse_mask = refuge_train_data.get_sparse_mask(\"contour\", mask, image, 1.0)\n",
                "# sparse_mask = (sparse_mask == 1).astype(sparse_mask.dtype)\n",
                "\n",
                "\n",
                "# def erosion(image, structure=None):\n",
                "#     return binary_erosion(image, structure=structure).astype(image.dtype)\n",
                "\n",
                "\n",
                "# def dilation(image, structure=None):\n",
                "#     return binary_dilation(image, structure=structure).astype(image.dtype)\n",
                "\n",
                "\n",
                "# def skeletonization(image, structure=None):\n",
                "#     skeleton = np.zeros_like(image)\n",
                "#     temp_image = image.copy()\n",
                "#     while np.any(temp_image):\n",
                "#         eroded = binary_erosion(temp_image, structure=structure)\n",
                "#         skeleton_layer = temp_image & ~binary_dilation(eroded, structure=structure)  # type: ignore\n",
                "#         skeleton |= skeleton_layer\n",
                "#         temp_image = eroded\n",
                "#     return skeleton\n",
                "\n",
                "\n",
                "# sparse_mask = erosion(sparse_mask)\n",
                "# sparse_mask = dilation(sparse_mask)\n",
                "# sparse_mask = dilation(sparse_mask) - sparse_mask\n",
                "# sparse_mask = skeletonization(sparse_mask)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from skimage.color import rgb2gray\n",
                "# from skimage.filters import sobel\n",
                "# from skimage.segmentation import (\n",
                "#     slic,\n",
                "#     felzenszwalb,\n",
                "#     quickshift,\n",
                "#     watershed,\n",
                "#     mark_boundaries,\n",
                "# )\n",
                "# from skimage.util import img_as_float\n",
                "\n",
                "# image, _, _ = refuge_train_data.get_data(2)\n",
                "\n",
                "# image_float = img_as_float(image)\n",
                "\n",
                "# segments_slic = slic(image_float, n_segments=100, compactness=10, start_label=1)\n",
                "\n",
                "# segments_felzenszwalb = felzenszwalb(image_float, scale=40, sigma=0.5, min_size=50)\n",
                "\n",
                "# segments_quickshift = quickshift(image_float, kernel_size=3, max_dist=15, ratio=0.5)\n",
                "\n",
                "# gradient = sobel(rgb2gray(image))\n",
                "# segments_watershed = watershed(gradient, markers=100, compactness=0.0005)  # type: ignore\n",
                "\n",
                "# image = mark_boundaries(image, segments_slic, color=(0, 0, 1))\n",
                "# image = mark_boundaries(image, segments_felzenszwalb, color=(0, 0, 1))\n",
                "# image = mark_boundaries(image, segments_quickshift, color=(0, 0, 1))\n",
                "# image = mark_boundaries(image, segments_watershed, color=(0, 0, 1))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_, axs = plt.subplots(1, 1, figsize=(6, 6))\n",
                "axs.axis(\"off\")\n",
                "axs.imshow(image, cmap=\"gray\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_, axs = plt.subplots(1, 1, figsize=(6, 6))\n",
                "axs.axis(\"off\")\n",
                "axs.imshow(sparse_mask, cmap=\"gray\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Region Analysis\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import altair as alt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\pandega\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
                        "  \"class\": algorithms.Blowfish,\n"
                    ]
                }
            ],
            "source": [
                "from skimage import segmentation\n",
                "from numpy.typing import NDArray\n",
                "\n",
                "from data.typings import FewSparseDatasetKwargs\n",
                "from tasks.optic_disc_cup.datasets import (\n",
                "    DrishtiTestFSDataset,\n",
                "    RefugeTestFSDataset,\n",
                "    RimOne3TestFSDataset,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_kwargs: FewSparseDatasetKwargs = {\n",
                "    \"seed\": 0,\n",
                "    \"split_val_fold\": 0,\n",
                "    \"split_test_fold\": 0,\n",
                "    \"cache_data\": True,\n",
                "    \"query_batch_size\": 5,\n",
                "    \"split_query_size\": 0.5,\n",
                "    \"split_query_fold\": 0,\n",
                "    \"shot_options\": [1, 5, 10, 15, 20],\n",
                "    \"sparsity_options\": [(\"region\", [0.1, 0.25, 0.5, 0.75, 1.0])],\n",
                "    \"support_query_data\": \"mixed\",\n",
                "    \"support_batch_mode\": \"full_permutation\",\n",
                "    \"split_test_size\": 1,\n",
                "    \"sparsity_params\": {\"region_segments\": 250, \"region_compactness\": 0.5},\n",
                "}\n",
                "\n",
                "drishti_dataset = DrishtiTestFSDataset(\n",
                "    mode=\"test\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    **(dataset_kwargs | {\"dataset_name\": \"DRISHTI-GS-test\"}),\n",
                ")\n",
                "refuge_dataset = RefugeTestFSDataset(\n",
                "    mode=\"test\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    **(dataset_kwargs | {\"dataset_name\": \"REFUGE-test\"}),\n",
                ")\n",
                "rim_one_3_dataset = RimOne3TestFSDataset(\n",
                "    mode=\"test\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    **(dataset_kwargs | {\"dataset_name\": \"RIM-ONE-3-test\"}),\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_region_coverage(\n",
                "    img: NDArray, msk: NDArray, segments: int, compactness: float\n",
                ") -> list[int]:\n",
                "    num_classes = 3\n",
                "    slic = segmentation.slic(\n",
                "        img, n_segments=segments, compactness=compactness, start_label=1\n",
                "    )\n",
                "    labels = np.unique(slic)\n",
                "\n",
                "    pure_regions = [[] for _ in range(num_classes)]\n",
                "    for label in labels:\n",
                "        sp = msk[slic == label].ravel()\n",
                "        cnt = np.bincount(sp)\n",
                "        for c in range(num_classes):\n",
                "            if (cnt[c] if c < len(cnt) else None) == cnt.sum():\n",
                "                pure_regions[c].append(label)\n",
                "\n",
                "    new_msk = np.zeros_like(msk)\n",
                "    new_msk[:] = -1\n",
                "    for c, pure_region in enumerate(pure_regions):\n",
                "        for sp in pure_region:\n",
                "            new_msk[slic == sp] = c\n",
                "\n",
                "    coverage_list = [sum([len(pr) for pr in pure_regions]), len(labels)]\n",
                "    for c in range(num_classes):\n",
                "        coverage_list.append(np.sum(new_msk == c))\n",
                "        coverage_list.append(np.sum(msk == c))\n",
                "\n",
                "    return coverage_list\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# region_segments_options = [50, 100, 150, 200, 250, 300, 350, 400]\n",
                "# region_compactness_options = [10**-1, 10**-0.5, 10**0, 10**0.5, 10**1, 10**1.5, 10**2]\n",
                "# region_options = [\n",
                "#     (s, c) for s in region_segments_options for c in region_compactness_options\n",
                "# ]\n",
                "\n",
                "# coverage_data = []\n",
                "# for i, (segments, compactness) in enumerate(region_options):\n",
                "#     print(f\" {i + 1}/{len(region_options)}\")\n",
                "#     for dataset in [drishti_dataset, refuge_dataset, rim_one_3_dataset]:\n",
                "#         name = dataset.dataset_name\n",
                "#         indices = set(dataset.query_indices)\n",
                "#         for i in indices:\n",
                "#             img, msk, _ = dataset.get_data(i)\n",
                "#             (\n",
                "#                 cover_seg,\n",
                "#                 total_seg,\n",
                "#                 cover_0,\n",
                "#                 total_0,\n",
                "#                 cover_1,\n",
                "#                 total_1,\n",
                "#                 cover_2,\n",
                "#                 total_2,\n",
                "#             ) = get_region_coverage(img, msk, segments, compactness)\n",
                "#             coverage_data.append(\n",
                "#                 {\n",
                "#                     \"segments\": segments,\n",
                "#                     \"compactness\": compactness,\n",
                "#                     \"dataset\": name,\n",
                "#                     \"index\": i,\n",
                "#                     \"covered_segments\": cover_seg,\n",
                "#                     \"total_segments\": total_seg,\n",
                "#                     \"covered_class_0\": cover_0,\n",
                "#                     \"total_class_0\": total_0,\n",
                "#                     \"covered_class_1\": cover_1,\n",
                "#                     \"total_class_1\": total_1,\n",
                "#                     \"covered_class_2\": cover_2,\n",
                "#                     \"total_class_2\": total_2,\n",
                "#                 }\n",
                "#             )\n",
                "\n",
                "# coverage_df = pd.DataFrame(coverage_data)\n",
                "# coverage_df.to_csv(\"logs/region_coverage.csv\", index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
