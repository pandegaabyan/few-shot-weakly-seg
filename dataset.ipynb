{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Dataset and Loader\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "from matplotlib import pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dummy Dataset\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from data.dummy_dataset import DummyFSDataset, DummySimpleDataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dummy_simple_dataset = DummySimpleDataset(\n",
                "    \"val\",\n",
                "    3,\n",
                "    (256, 256),\n",
                "    max_items=100,\n",
                "    seed=0,\n",
                "    split_val_size=0.2,\n",
                "    split_val_fold=0,\n",
                "    split_test_size=0.2,\n",
                "    split_test_fold=0,\n",
                "    cache_data=False,\n",
                "    dataset_name=\"Dummy\",\n",
                ")\n",
                "\n",
                "print(len(dummy_simple_dataset))\n",
                "img, msk, name, _ = dummy_simple_dataset[79]\n",
                "\n",
                "print(\n",
                "    name,\n",
                "    img.shape,\n",
                "    img.dtype,\n",
                "    img.min(),\n",
                "    img.max(),\n",
                "    msk.shape,\n",
                "    msk.dtype,\n",
                "    torch.unique(msk),\n",
                ")\n",
                "\n",
                "plt.imshow(np.moveaxis(img.numpy(), 0, -1))\n",
                "# plt.imshow(msk.numpy())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dummy_fs_dataset = DummyFSDataset(\n",
                "    \"train\",\n",
                "    3,\n",
                "    (256, 256),\n",
                "    max_items=25,\n",
                "    seed=0,\n",
                "    split_val_size=0.2,\n",
                "    split_val_fold=0,\n",
                "    split_test_size=0.2,\n",
                "    split_test_fold=0,\n",
                "    cache_data=False,\n",
                "    dataset_name=\"Dummy\",\n",
                "    shot_options=\"all\",\n",
                "    sparsity_options=[\n",
                "        (\"point\", [1, 5, 10, 20]),\n",
                "        (\"grid\", (10, 20)),\n",
                "        (\"contour\", \"random\"),\n",
                "        (\"skeleton\", (0.1, 0.5)),\n",
                "        (\"region\", 0.5),\n",
                "    ],\n",
                "    sparsity_params={},\n",
                "    shot_sparsity_permutation=True,\n",
                "    homogen_support_batch=True,\n",
                "    query_batch_size=10,\n",
                "    split_query_size=0.5,\n",
                "    split_query_fold=0,\n",
                "    num_iterations=5.0,\n",
                ")\n",
                "\n",
                "print(len(dummy_fs_dataset.items))\n",
                "print(len(dummy_fs_dataset), dummy_fs_dataset.num_iterations)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(dummy_fs_dataset.support_batches)\n",
                "for i in range(len(dummy_fs_dataset)):\n",
                "    support, query, _ = dummy_fs_dataset[i]\n",
                "    supp_img, supp_msk, supp_name, supp_sparsity_mode, supp_sparsity_value = support\n",
                "    qry_img, qry_msk, qry_name = query\n",
                "    print(\n",
                "        supp_img.shape[0],\n",
                "        supp_msk.shape[0],\n",
                "        len(supp_name),\n",
                "        \"|\",\n",
                "        supp_sparsity_mode,\n",
                "        [round(v, 2) if isinstance(v, float) else v for v in supp_sparsity_value]\n",
                "        if isinstance(supp_sparsity_value, list)\n",
                "        else supp_sparsity_value,\n",
                "        \"|\",\n",
                "        qry_img.shape[0],\n",
                "        qry_msk.shape[0],\n",
                "        len(qry_name),\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "support, query, _ = dummy_fs_dataset[0]\n",
                "\n",
                "supp_img, supp_msk, supp_name, supp_sparsity_mode, supp_sparsity_value = support\n",
                "qry_img, qry_msk, qry_name = query\n",
                "\n",
                "print(\n",
                "    supp_img.shape,\n",
                "    supp_img.dtype,\n",
                "    supp_img.min(),\n",
                "    supp_img.max(),\n",
                "    supp_msk.shape,\n",
                "    supp_msk.dtype,\n",
                "    torch.unique(supp_msk),\n",
                ")\n",
                "print(supp_name, supp_sparsity_mode, supp_sparsity_value)\n",
                "print(\n",
                "    qry_img.shape,\n",
                "    qry_img.dtype,\n",
                "    qry_img.min(),\n",
                "    qry_img.max(),\n",
                "    qry_msk.shape,\n",
                "    qry_msk.dtype,\n",
                "    torch.unique(qry_msk),\n",
                ")\n",
                "print(qry_name)\n",
                "print()\n",
                "\n",
                "# plt.imshow(supp_msk[0].numpy())\n",
                "# plt.imshow(qry_msk[0].numpy())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dummy Loader\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch.utils.data import ConcatDataset, DataLoader\n",
                "\n",
                "dummy_loader = DataLoader(\n",
                "    ConcatDataset([dummy_fs_dataset]),\n",
                "    batch_size=None,\n",
                "    shuffle=dummy_fs_dataset.mode == \"train\",\n",
                "    num_workers=0,\n",
                "    pin_memory=True,\n",
                ")\n",
                "\n",
                "for batch in dummy_loader:\n",
                "    support, query, dataset_name = batch\n",
                "\n",
                "    print(type(batch.support))\n",
                "    print(support[0].shape, support[1].shape, support[2][:4], support[3])\n",
                "    print(query[0].shape, query[1].shape, query[2])\n",
                "    print(dataset_name)\n",
                "\n",
                "    break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sparse Masks\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from matplotlib import pyplot as plt\n",
                "\n",
                "from data.few_sparse_dataset import FewSparseDataset\n",
                "from data.typings import SparsityValue\n",
                "from tasks.optic_disc_cup.datasets import (\n",
                "    RimOne3TrainFSDataset,\n",
                "    DrishtiTrainFSDataset,\n",
                "    RefugeTrainFSDataset,\n",
                "    RefugeValFSDataset,\n",
                ")\n",
                "\n",
                "plt.style.use(\"dark_background\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sparsity_values: dict[str, SparsityValue] = {\n",
                "    \"point\": 25,\n",
                "    \"grid\": 0.5,\n",
                "    \"contour\": 0.5,\n",
                "    \"skeleton\": 0.5,\n",
                "    \"region\": 0.5,\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def print_image_mask(image, mask):\n",
                "    print(image.shape, image.dtype, image.min(), image.max())\n",
                "    print(mask.shape, mask.dtype, np.unique(mask))\n",
                "\n",
                "\n",
                "def plot_masks(mask, sparse_masks):\n",
                "    n_rows = int(np.floor(len(sparse_masks) / 2)) + 1\n",
                "    _, axs = plt.subplots(n_rows, 2, figsize=(5, n_rows * 2.5))\n",
                "    assert isinstance(axs, np.ndarray)\n",
                "    axs = axs.flat\n",
                "    [ax.axis(\"off\") for ax in axs]\n",
                "    axs[0].imshow(mask)\n",
                "    for i, sm in enumerate(sparse_masks.values()):\n",
                "        axs[i + 1].imshow(sm)\n",
                "    plt.tight_layout()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_multiple_images_masks(\n",
                "    dataset: FewSparseDataset, indices: list[int], keys: list[str]\n",
                "):\n",
                "    ncols = len(indices)\n",
                "    nrows = len(keys)\n",
                "    _, axs = plt.subplots(nrows, ncols, figsize=(ncols * 2, nrows * 2))\n",
                "    assert isinstance(axs, np.ndarray)\n",
                "    for c, index in enumerate(indices):\n",
                "        image, mask, sparse_masks, _ = dataset.get_data_with_sparse_all(\n",
                "            index, sparsity_values\n",
                "        )\n",
                "        r = 0\n",
                "        if \"image\" in keys:\n",
                "            axs[r, c].imshow(image)\n",
                "            axs[r, c].axis(\"off\")\n",
                "            r += 1\n",
                "        if \"dense\" in keys:\n",
                "            axs[r, c].imshow(mask)\n",
                "            axs[r, c].axis(\"off\")\n",
                "            r += 1\n",
                "        for key, sm in sparse_masks.items():\n",
                "            if key not in keys:\n",
                "                continue\n",
                "            axs[r, c].imshow(sm)\n",
                "            axs[r, c].axis(\"off\")\n",
                "            r += 1\n",
                "    plt.tight_layout()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## RIM-ONE-3-train\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rim_one_3_sparsity_params: dict = {\n",
                "    \"point_dot_size\": 10,\n",
                "    \"grid_spacing\": 25,\n",
                "    \"grid_dot_size\": 7,\n",
                "    \"contour_radius_dist\": 5,\n",
                "    \"contour_radius_thick\": 2.5,\n",
                "    \"skeleton_radius_thick\": 5,\n",
                "    \"region_compactness\": 0.4,\n",
                "}\n",
                "\n",
                "rim_one_3_train_data = RimOne3TrainFSDataset(\n",
                "    mode=\"train\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    sparsity_params=rim_one_3_sparsity_params,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# image, mask, sparse_masks, _ = rim_one_3_data.get_data_with_sparse_all(0, sparsity_values)\n",
                "# print_image_mask(image, mask)\n",
                "# plot_masks(mask, sparse_masks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_multiple_images_masks(\n",
                "    rim_one_3_train_data,\n",
                "    list(range(0, 8)),\n",
                "    [\"point\", \"grid\", \"contour\", \"skeleton\", \"region\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## DRISHTI-GS-train\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "drishti_sparsity_params: dict = {\n",
                "    \"point_dot_size\": 10,\n",
                "    \"grid_spacing\": 25,\n",
                "    \"grid_dot_size\": 7,\n",
                "    \"contour_radius_dist\": 5,\n",
                "    \"contour_radius_thick\": 2,\n",
                "    \"skeleton_radius_thick\": 5,\n",
                "    \"region_compactness\": 0.5,\n",
                "}\n",
                "\n",
                "drishti_train_data = DrishtiTrainFSDataset(\n",
                "    mode=\"train\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    sparsity_params=drishti_sparsity_params,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_multiple_images_masks(\n",
                "    drishti_train_data,\n",
                "    list(range(0, 8)),\n",
                "    [\"point\", \"grid\", \"contour\", \"skeleton\", \"region\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## REFUGE-train\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "refuge_train_sparsity_params: dict = {\n",
                "    \"point_dot_size\": 10,\n",
                "    \"grid_spacing\": 25,\n",
                "    \"grid_dot_size\": 7,\n",
                "    \"contour_radius_dist\": 7,\n",
                "    \"contour_radius_thick\": 3,\n",
                "    \"skeleton_radius_thick\": 5,\n",
                "    \"region_compactness\": 0.4,\n",
                "}\n",
                "\n",
                "refuge_train_data = RefugeTrainFSDataset(\n",
                "    mode=\"train\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    sparsity_params=refuge_train_sparsity_params,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_multiple_images_masks(\n",
                "    refuge_train_data,\n",
                "    list(range(0, 8)),\n",
                "    [\"point\", \"grid\", \"contour\", \"skeleton\", \"region\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## REFUGE-val\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "refuge_val_sparsity_params: dict = {\n",
                "    \"point_dot_size\": 10,\n",
                "    \"grid_spacing\": 25,\n",
                "    \"grid_dot_size\": 7,\n",
                "    \"contour_radius_dist\": 7,\n",
                "    \"contour_radius_thick\": 3,\n",
                "    \"skeleton_radius_thick\": 5,\n",
                "    \"region_compactness\": 0.5,\n",
                "}\n",
                "\n",
                "refuge_val_data = RefugeValFSDataset(\n",
                "    mode=\"train\",\n",
                "    num_classes=3,\n",
                "    resize_to=(256, 256),\n",
                "    sparsity_params=refuge_val_sparsity_params,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_multiple_images_masks(\n",
                "    refuge_val_data,\n",
                "    list(range(0, 8)),\n",
                "    [\"point\", \"grid\", \"contour\", \"skeleton\", \"region\"],\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
