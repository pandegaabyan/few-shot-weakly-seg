{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Dataset and Loader\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "from matplotlib import pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dummy Dataset\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from data.dummy_dataset import DummyFSDataset, DummySimpleDataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dummy_simple_dataset = DummySimpleDataset(\n",
                "    \"val\",\n",
                "    3,\n",
                "    (256, 256),\n",
                "    max_items=100,\n",
                "    seed=0,\n",
                "    split_val_size=0.2,\n",
                "    split_test_size=0.2,\n",
                "    dataset_name=\"Dummy\",\n",
                ")\n",
                "\n",
                "print(len(dummy_simple_dataset))\n",
                "img, msk, name, _ = dummy_simple_dataset[79]\n",
                "\n",
                "print(\n",
                "    name,\n",
                "    img.shape,\n",
                "    img.dtype,\n",
                "    img.min(),\n",
                "    img.max(),\n",
                "    msk.shape,\n",
                "    msk.dtype,\n",
                "    torch.unique(msk),\n",
                ")\n",
                "\n",
                "plt.imshow(np.moveaxis(img.numpy(), 0, -1))\n",
                "# plt.imshow(msk.numpy())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dummy_fs_dataset = DummyFSDataset(\n",
                "    \"train\",\n",
                "    3,\n",
                "    (256, 256),\n",
                "    max_items=100,\n",
                "    seed=0,\n",
                "    split_val_size=0.2,\n",
                "    split_test_size=0.2,\n",
                "    dataset_name=\"Dummy\",\n",
                "    shot_options=[1, 5, 10, 20],\n",
                "    # shot_options=\"all\",\n",
                "    sparsity_options=[\n",
                "        (\"point\", [1, 5, 10, 20]),\n",
                "        # (\"grid\", (10, 20)),\n",
                "        # (\"contour\", \"random\"),\n",
                "        # (\"skeleton\", (0.1, 0.5)),\n",
                "        # (\"region\", 0.5),\n",
                "    ],\n",
                "    shot_sparsity_permutation=True,\n",
                "    num_iterations=1.0,\n",
                "    query_batch_size=5,\n",
                "    split_query_size=0.9,\n",
                ")\n",
                "\n",
                "print(len(dummy_fs_dataset))\n",
                "support, query, _ = dummy_fs_dataset[0]\n",
                "\n",
                "supp_img, supp_msk, supp_name, supp_sparsity_mode, supp_sparsity_value = support\n",
                "qry_img, qry_msk, qry_name = query\n",
                "\n",
                "print(\n",
                "    supp_img.shape,\n",
                "    supp_img.dtype,\n",
                "    supp_img.min(),\n",
                "    supp_img.max(),\n",
                "    supp_msk.shape,\n",
                "    supp_msk.dtype,\n",
                "    torch.unique(supp_msk),\n",
                ")\n",
                "print(supp_name, supp_sparsity_mode, supp_sparsity_value)\n",
                "print(\n",
                "    qry_img.shape,\n",
                "    qry_img.dtype,\n",
                "    qry_img.min(),\n",
                "    qry_img.max(),\n",
                "    qry_msk.shape,\n",
                "    qry_msk.dtype,\n",
                "    torch.unique(qry_msk),\n",
                ")\n",
                "print(qry_name)\n",
                "print()\n",
                "\n",
                "# plt.imshow(supp_msk[0].numpy())\n",
                "# plt.imshow(qry_msk[0].numpy())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(dummy_fs_dataset.support_batches)\n",
                "for i in range(len(dummy_fs_dataset)):\n",
                "    support, query, _ = dummy_fs_dataset[i]\n",
                "    supp_img, supp_msk, supp_name, supp_sparsity_mode, supp_sparsity_value = support\n",
                "    qry_img, qry_msk, qry_name = query\n",
                "    print(\n",
                "        supp_img.shape[0],\n",
                "        supp_msk.shape[0],\n",
                "        len(supp_name),\n",
                "        supp_sparsity_mode,\n",
                "        supp_sparsity_value,\n",
                "        qry_img.shape[0],\n",
                "        qry_msk.shape[0],\n",
                "        len(qry_name),\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dummy Loader\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch.utils.data import ConcatDataset, DataLoader\n",
                "\n",
                "dummy_loader = DataLoader(\n",
                "    ConcatDataset([dummy_fs_dataset]),\n",
                "    batch_size=None,\n",
                "    shuffle=dummy_fs_dataset.mode == \"train\",\n",
                "    num_workers=0,\n",
                "    pin_memory=True,\n",
                ")\n",
                "\n",
                "for batch in dummy_loader:\n",
                "    support, query, dataset_name = batch\n",
                "\n",
                "    print(type(batch.support))\n",
                "    print(support[0].shape, support[1].shape, support[2][:4], support[3])\n",
                "    print(query[0].shape, query[1].shape, query[2])\n",
                "    print(dataset_name)\n",
                "\n",
                "    break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## RIM-ONE Dataset\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tasks.optic_disc_cup.datasets import RimOneFSDataset\n",
                "\n",
                "\n",
                "rim_one = RimOneFSDataset(\n",
                "    \"train\",\n",
                "    3,\n",
                "    (256, 256),\n",
                "    max_items=100,\n",
                "    seed=0,\n",
                "    split_val_size=0.2,\n",
                "    split_test_size=0.2,\n",
                "    dataset_name=\"RIM-ONE DL\",\n",
                "    shot_options=[1, 5, 10, 20],\n",
                "    sparsity_options=[\n",
                "        (\"point\", [1, 5, 10, 20]),\n",
                "        (\"grid\", [20, 10]),\n",
                "        (\"contour\", [0.1, 0.5, 1]),\n",
                "    ],\n",
                "    shot_sparsity_permutation=True,\n",
                "    query_batch_size=2,\n",
                "    split_query_size=0.5,\n",
                ")\n",
                "\n",
                "# for i in range(rim_one.num_iterations):\n",
                "#     print(rim_one.support_batches[i], rim_one.support_sparsities[i])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
